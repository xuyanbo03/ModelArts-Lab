{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然语言处理实战——命名实体识别\n",
    "\n",
    "在前面的六期实战营案例中，无论是图像分类还是物体识别，都是对于图像的处理。\n",
    "\n",
    "从本期实战营开始，我们进入到人工智能的另一大重要领域——自然语言处理（NLP，Natural Language Processing）。\n",
    "\n",
    "自然语言处理是人工智能最重要，也是最困难的领域之一，其任务大概可以分为以下几类：\n",
    "\n",
    "- 词法分析：分词、词性标注、拼写校正等\n",
    "\n",
    "\n",
    "- 分类任务：文本分类、情感计算等\n",
    "\n",
    "\n",
    "- 信息抽取：命名实体识别、实体消歧、术语抽取、关系抽取等\n",
    "\n",
    "\n",
    "- 顶层任务：机器翻译、文本摘要、问答系统、阅读理解等\n",
    "\n",
    "在接下来的四期中，我们将接触到四个自然语言处理的任务，同学们有没很期待！\n",
    "\n",
    "首先准备实战环境。\n",
    "\n",
    "### 进入ModelArts\n",
    "\n",
    "点击如下链接：https://www.huaweicloud.com/product/modelarts.html ， 进入ModelArts主页。点击“立即使用”按钮，输入用户名和密码登录，进入ModelArts使用页面。\n",
    "\n",
    "### 创建ModelArts notebook\n",
    "\n",
    "下面，我们在ModelArts中创建一个notebook开发环境，ModelArts notebook提供网页版的Python开发环境，可以方便的编写、运行代码，并查看运行结果。\n",
    "\n",
    "第一步：在ModelArts服务主界面依次点击“开发环境”、“创建”\n",
    "\n",
    "![create_nb_create_button](./img/create_nb_create_button.png)\n",
    "\n",
    "第二步：填写notebook所需的参数：\n",
    "\n",
    "![jupyter](./img/notebook1.png)\n",
    "\n",
    "第三步：配置好notebook参数后，点击下一步，进入notebook信息预览。确认无误后，点击“立即创建”\n",
    "![jupyter](./img/notebook2.png)\n",
    "\n",
    "第四步：创建完成后，返回开发环境主界面，等待Notebook创建完毕后，打开Notebook，进行下一步操作。\n",
    "![modelarts_notebook_index](./img/modelarts_notebook_index.png)\n",
    "\n",
    "### 在ModelArts中创建开发环境\n",
    "\n",
    "接下来，我们创建一个实际的开发环境，用于后续的实验步骤。\n",
    "\n",
    "第一步：点击下图所示的“启动”按钮，加载后“打开”按钮变从灰色变为蓝色后点击“打开”进入刚刚创建的Notebook\n",
    "![jupyter](./img/notebook3.png)\n",
    "![jupyter](./img/notebook4.png)\n",
    "\n",
    "\n",
    "第二步：创建一个Python3环境的的Notebook。点击右上角的\"New\"，然后选择TensorFlow 1.13.1开发环境。\n",
    "\n",
    "第三步：点击左上方的文件名\"Untitled\"，并输入一个与本实验相关的名称，如\"ner\"\n",
    "![notebook_untitled_filename](./img/notebook_untitled_filename.png)\n",
    "![notebook_name_the_ipynb](./img/notebook_name_the_ipynb.png)\n",
    "\n",
    "\n",
    "### 在Notebook中编写并执行代码\n",
    "\n",
    "在Notebook中，我们输入一个简单的打印语句，然后点击上方的运行按钮，可以查看语句执行的结果：\n",
    "![run_helloworld](./img/run_helloworld.png)\n",
    "\n",
    "\n",
    "开发环境准备好啦，接下来可以愉快地写代码啦！\n",
    "\n",
    "\n",
    "### 准备源代码和数据\n",
    "\n",
    "准备案例所需的源代码和数据，相关资源已经保存在 OBS 中，我们通过 ModelArts SDK 将资源下载到本地。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully download file modelarts-labs-bj4/notebook/DL_nlp_ner/ner.tar.gz from OBS to local ./ner.tar.gz\n",
      "total 375356\r\n",
      "drwxr-x--- 5 ma-user ma-group      4096 Nov 19 18:03 .\r\n",
      "drwxrwxrwx 3 ma-user ma-group      4096 Nov 19 17:25 ..\r\n",
      "drwxr-x--- 2 ma-user ma-group      4096 Nov 19 17:15 img\r\n",
      "drwxr-x--- 2 ma-user ma-group      4096 Nov 19 18:00 .ipynb_checkpoints\r\n",
      "drwxr-x--- 7 ma-user ma-group      4096 Sep  9  2019 ner\r\n",
      "-rw-r----- 1 ma-user ma-group     56192 Nov 19 18:02 ner.ipynb\r\n",
      "-rw-r----- 1 ma-user ma-group 384141687 Nov 19 18:03 ner.tar.gz\r\n",
      "-rw-r----- 1 ma-user ma-group     68329 Nov 19 18:00 nlp_ner-Copy1.ipynb\r\n",
      "-rw-r----- 1 ma-user ma-group     68329 Nov 19 18:00 nlp_ner.ipynb\r\n",
      "-rw-r----- 1 ma-user ma-group       431 Nov 18 10:18 README.md\r\n"
     ]
    }
   ],
   "source": [
    "from modelarts.session import Session\n",
    "session = Session()\n",
    "\n",
    "if session.region_name == 'cn-north-1':\n",
    "    bucket_path = 'modelarts-labs/notebook/DL_nlp_ner/ner.tar.gz'\n",
    "    \n",
    "elif session.region_name == 'cn-north-4':\n",
    "    bucket_path = 'modelarts-labs-bj4/notebook/DL_nlp_ner/ner.tar.gz'\n",
    "else:\n",
    "    print(\"请更换地区到北京一或北京四\")\n",
    "    \n",
    "session.download_data(bucket_path=bucket_path, path='./ner.tar.gz')\n",
    "\n",
    "!ls -la   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解压从obs下载的压缩包，解压后删除压缩包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 216\r\n",
      "drwxr-x--- 5 ma-user ma-group  4096 Nov 19 18:03 .\r\n",
      "drwxrwxrwx 3 ma-user ma-group  4096 Nov 19 17:25 ..\r\n",
      "drwxr-x--- 2 ma-user ma-group  4096 Nov 19 17:15 img\r\n",
      "drwxr-x--- 2 ma-user ma-group  4096 Nov 19 18:00 .ipynb_checkpoints\r\n",
      "drwxr-x--- 7 ma-user ma-group  4096 Sep  9  2019 ner\r\n",
      "-rw-r----- 1 ma-user ma-group 56192 Nov 19 18:02 ner.ipynb\r\n",
      "-rw-r----- 1 ma-user ma-group 68329 Nov 19 18:00 nlp_ner-Copy1.ipynb\r\n",
      "-rw-r----- 1 ma-user ma-group 68329 Nov 19 18:00 nlp_ner.ipynb\r\n",
      "-rw-r----- 1 ma-user ma-group   431 Nov 18 10:18 README.md\r\n"
     ]
    }
   ],
   "source": [
    "# 解压\n",
    "!tar xf ./ner.tar.gz\n",
    "\n",
    "# 删除\n",
    "!rm ./ner.tar.gz\n",
    "\n",
    "!ls -la    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 命名实体识别简介\n",
    "\n",
    "在自然语言处理任务中，命名实体识别是最为基础的任务之一，为信息抽取、信息检索、机器翻译、问答系统等高阶任务做铺垫。\n",
    "\n",
    "文本中的人名、地名、组织机构名等统一称之为命名实体。\n",
    "\n",
    "在本实战中，选择使用BIO标注：将每个元素标注为“B-X”、“I-X”或者“O”。\n",
    "\n",
    "- B-PER、I-PER 代表人名首字、人名非首字\n",
    "\n",
    "\n",
    "- B-LOC、I-LOC 代表地名首字、地名非首字\n",
    "\n",
    "\n",
    "- B-ORG、I-ORG 代表组织机构名首字、组织机构名非首字\n",
    "\n",
    "\n",
    "- O 代表非命名实体\n",
    "\n",
    "示例如下：\n",
    "\n",
    "![](./img/BIO.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelArts 命名实体标注功能\n",
    "\n",
    "本部分将介绍通过 ModelArts 的命名实体标注功能：针对文本中的实体字段进行标注，如“时间”、“地点”等。\n",
    "\n",
    "登录 ModelArts 管理控制台，在左侧菜单栏中选择`数据标注`，进入`数据集`管理页面。\n",
    "\n",
    "点击`创建数据集`，准备用于数据标注的文本数据。\n",
    "\n",
    "![](./img/data_tagging.png)\n",
    "\n",
    "#### 准备未标注数据集\n",
    "\n",
    "首先需要在 OBS 中创建一个数据集，后续的操作如标注数据、数据集发布等，都是基于创建和管理的数据集。\n",
    "\n",
    "OBS 链接在这里：https://www.huaweicloud.com/product/obs0.html\n",
    "\n",
    "数据标注功能需要获取访问 OBS 权限，在未进行委托授权之前，无法使用此功能。需要可以在`数据标注`页面，单击`服务授权`，由具备授权的账号`同意授权`后，即可使用。\n",
    "\n",
    "创建用于存储数据的 OBS 桶及文件夹。本实践中桶名设定为`ner-tagging`，**请用户建立新桶并自定义命名，OBS桶名全局唯一，若创建时桶名冲突，请选择其他不冲突桶名**。\n",
    "\n",
    "桶创建成功后，在桶中创建标注输入和标注输出的文件夹，并将用于标注是文本文件上传到输入文件夹中。\n",
    "\n",
    "文本标注文件的要求为：**文件格式要求 txt 或者 csv，文件大小不超过 8M，以换行符作为分隔符，每行数据代表一个标注对象。**\n",
    "\n",
    "在本实践中使用的示例标注文件`text.txt`可以[点此下载](https://modelarts-labs.obs.cn-north-1.myhuaweicloud.com/notebook/DL_nlp_ner/text.tar.gz)，解压后可上传到输入文件夹中按照本案例步骤使用。\n",
    "\n",
    "在本实践中创建文件夹结构示例如下：\n",
    "\n",
    "```\n",
    "tagging\n",
    "   │\n",
    "   ├─input\n",
    "   │       └─text.txt\n",
    "   └─output\n",
    "```\n",
    "\n",
    "其中\n",
    "\n",
    "- `input`   为命名实体输入文件夹\n",
    "- `text.txt`   为命名实体输入文本文件\n",
    "- `output`   为命名实体输出文件夹\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建命名实体任务数据集，如下图所示\n",
    "\n",
    "![](./img/tagging_ner_1.png)\n",
    "\n",
    "注意创建参数\n",
    "\n",
    "- 名称：可自定义数据集名称，本案例中设定为`ner-tagging`\n",
    "- 数据集输入位置：本案例中设定为`/ner-tagging/tagging/input/`\n",
    "- 数据集输出位置：本案例中设定为`/ner-tagging/tagging/output/`\n",
    "- 标注场景：选择`文本`\n",
    "- 标注类型：选择`命名实体`\n",
    "- 添加标签集：可自定义标签名称、个数、颜色。本案例中设定三个分类标签：`人物`标签为蓝色；`时间`标签为绿色；`地点`标签为红色。\n",
    "\n",
    "完成以上设定后，点击右下角`创建`。命名实体数据集创建完成后，系统自动跳转至数据集管理页面。\n",
    "\n",
    "![](./img/tagging_ner_2.png)\n",
    "\n",
    "点击数据集名称，进入标注界面。选择未标注对象，点击标签进行标注，如图所示\n",
    "\n",
    "![](./img/tagging_ner_3.png)\n",
    "\n",
    "选择标注对象：`明天张亮要去体育场打篮球。`\n",
    "\n",
    "- 选取“明天”字段，选择标签`时间`\n",
    "- 选取“张亮”字段，选择标签`人物`\n",
    "- 选取“体育场”字段，选择标签`地点`\n",
    "\n",
    "然后点击下方`保存当前页`进行保存。\n",
    "\n",
    "继续选择其他标注对象，按上述方法进行标注。若需增加标注数据，点击左上角的`添加文件`即可自行增加标注文本。数据全部标注完成后（本样例中仅提供三条命名实体文本），点击`已标注`可查看标注结果。\n",
    "\n",
    "![](./img/tagging_ner_4.png)\n",
    "\n",
    "点击`返回数据集`，可以看到数据集已全部标注成功。\n",
    "\n",
    "![](./img/tagging_ner_5.png)\n",
    "\n",
    "针对刚创建的数据集（未发布前），无数据集版本信息，必须执行发布操作后，才能应用于模型开发或训练。\n",
    "\n",
    "点击`发布`，可以编辑版本名称，本案例中为默认`V001`。\n",
    "\n",
    "![](./img/tagging_ner_6.png)\n",
    "\n",
    "发布成功如图所示。\n",
    "\n",
    "![](./img/tagging_ner_7.png)\n",
    "\n",
    "可以查看数据集版本的 “名称”、 “状态”、 “文件总数”、 “已标注文件个数”，并在左侧的 “演进过程”中查看版本的发布时间。\n",
    "\n",
    "随后可以使用标注成功的数据集，标注结果储存在`output`文件夹中。\n",
    "\n",
    "后续 ModelArts 将会上线**智能标注**功能，相信大家已经体验过第二期实战的图像智能标注，能够快速完成数据标注，节省70%以上的标注时间。智能标注是指基于当前标注阶段的标签及学习训练，选中系统中已有的模型进行智能标注，快速完成剩余数据的标注操作。请持续关注数据标注功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "\n",
    "本实践使用的是《人民日报1998年中文标注语料库》。\n",
    "\n",
    "数据集格式为：每行的第一个是字，第二个是它的标签，字与标签之间使用空格分隔，两句话之间空一行。如下图所示：\n",
    "\n",
    "![](./img/数据集示例.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.11.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ce/d5/38cd4543401708e64c9ee6afa664b936860f4630dd93a49ab863f9998cd2/tensorflow-1.11.0-cp36-cp36m-manylinux1_x86_64.whl (63.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 63.0MB 21.2MB/s ta 0:00:011��███▏                    | 22.0MB 105.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.5 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.3 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Collecting setuptools<=39.1.0 (from tensorflow==1.11.0)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
      "\u001b[K    100% |████████████████████████████████| 573kB 39.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Collecting tensorboard<1.12.0,>=1.11.0 (from tensorflow==1.11.0)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/9b/2f/4d788919b1feef04624d63ed6ea45a49d1d1c834199ec50716edb5d310f4/tensorboard-1.11.0-py3-none-any.whl (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.0MB 44.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow==1.11.0)\n",
      "Requirement already satisfied: h5py in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from keras-applications>=1.0.5->tensorflow==1.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0)\n",
      "Installing collected packages: setuptools, tensorboard, tensorflow\n",
      "  Found existing installation: setuptools 41.0.0\n",
      "    Uninstalling setuptools-41.0.0:\n",
      "      Successfully uninstalled setuptools-41.0.0\n",
      "  Found existing installation: tensorboard 1.13.1\n",
      "    Uninstalling tensorboard-1.13.1:\n",
      "      Successfully uninstalled tensorboard-1.13.1\n",
      "Successfully installed setuptools-39.1.0 tensorboard-1.11.0 tensorflow-1.11.0\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow-gpu==1.11.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/25/52/01438b81806765936eee690709edc2a975472c4e9d8d465a01840869c691/tensorflow_gpu-1.11.0-cp36-cp36m-manylinux1_x86_64.whl (258.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 258.8MB 101.2MB/s ta 0:00:01MB/s eta 0:00:02                          | 19.9MB 120.7MB/s eta 0:00:02                    | 24.0MB 90.4MB/s eta 0:00:03  | 36.3MB 114.7MB/s eta 0:00:026% |█████▎                          | 42.6MB 117.9MB/s eta 0:00:02��██▊                          | 46.4MB 87.6MB/s eta 0:00:03                 | 51.5MB 133.7MB/s eta 0:00:02████▏                        | 57.6MB 108.7MB/s eta 0:00:0224% |███████▉                        | 63.2MB 126.7MB/s eta 0:00:02020:02██████ | 250.0MB 102.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.3 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.5 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: tensorboard<1.12.0,>=1.11.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: h5py in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from keras-applications>=1.0.5->tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow-gpu==1.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow-gpu==1.11.0)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "  Found existing installation: tensorflow-gpu 1.13.1\n",
      "    Uninstalling tensorflow-gpu-1.13.1:\n",
      "      Successfully uninstalled tensorflow-gpu-1.13.1\n",
      "Successfully installed tensorflow-gpu-1.11.0\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.11.0\n",
    "\n",
    "!pip install tensorflow-gpu==1.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入Python库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import codecs\n",
    "import pickle\n",
    "import collections\n",
    "from ner.bert import modeling, optimization, tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义路径及参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./ner/data\"    \n",
    "output_dir = \"./ner/output\"    \n",
    "vocab_file = \"./ner/chinese_L-12_H-768_A-12/vocab.txt\"    \n",
    "data_config_path = \"./ner/chinese_L-12_H-768_A-12/bert_config.json\"    \n",
    "init_checkpoint = \"./ner/chinese_L-12_H-768_A-12/bert_model.ckpt\"    \n",
    "max_seq_length = 128    \n",
    "batch_size = 64    \n",
    "num_train_epochs = 5.0    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义processor类获取数据，打印标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'X', '[CLS]', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "from ner.src.models import InputFeatures, InputExample, DataProcessor, NerProcessor\n",
    "\n",
    "processors = {\"ner\": NerProcessor }\n",
    "processor = processors[\"ner\"](output_dir)\n",
    "\n",
    "label_list = processor.get_labels()\n",
    "print(\"labels:\", label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载预训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "显示配置信息:\n",
      "attention_probs_dropout_prob:0.1\n",
      "directionality:bidi\n",
      "hidden_act:gelu\n",
      "hidden_dropout_prob:0.1\n",
      "hidden_size:768\n",
      "initializer_range:0.02\n",
      "intermediate_size:3072\n",
      "max_position_embeddings:512\n",
      "num_attention_heads:12\n",
      "num_hidden_layers:12\n",
      "pooler_fc_size:768\n",
      "pooler_num_attention_heads:12\n",
      "pooler_num_fc_layers:3\n",
      "pooler_size_per_head:128\n",
      "pooler_type:first_token_transform\n",
      "type_vocab_size:2\n",
      "vocab_size:21128\n",
      "num_train_steps:1630\n",
      "num_warmup_steps:163\n",
      "num_train_size:20864\n"
     ]
    }
   ],
   "source": [
    "data_config = json.load(codecs.open(data_config_path))\n",
    "train_examples = processor.get_train_examples(data_dir)    \n",
    "num_train_steps = int(len(train_examples) / batch_size * num_train_epochs)    \n",
    "num_warmup_steps = int(num_train_steps * 0.1)   \n",
    "data_config['num_train_steps'] = num_train_steps\n",
    "data_config['num_warmup_steps'] = num_warmup_steps\n",
    "data_config['num_train_size'] = len(train_examples)\n",
    "\n",
    "print(\"显示配置信息:\")\n",
    "for key,value in data_config.items():\n",
    "    print('{key}:{value}'.format(key = key, value = value))\n",
    "\n",
    "bert_config = modeling.BertConfig.from_json_file(data_config_path)\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=True)\n",
    "\n",
    "#tf.estimator运行参数\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=output_dir,\n",
    "    save_summary_steps=1000,\n",
    "    save_checkpoints_steps=1000,\n",
    "    session_config=tf.ConfigProto(\n",
    "        log_device_placement=False,\n",
    "        inter_op_parallelism_threads=0,\n",
    "        intra_op_parallelism_threads=0,\n",
    "        allow_soft_placement=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取数据，获取句向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 20864\n",
      "INFO:tensorflow:Writing example 5000 of 20864\n",
      "INFO:tensorflow:Writing example 10000 of 20864\n",
      "INFO:tensorflow:Writing example 15000 of 20864\n",
      "INFO:tensorflow:Writing example 20000 of 20864\n"
     ]
    }
   ],
   "source": [
    "def convert_single_example(ex_index, example, label_list, max_seq_length, \n",
    "                           tokenizer, output_dir, mode):\n",
    "    label_map = {}\n",
    "    for (i, label) in enumerate(label_list, 1):\n",
    "        label_map[label] = i\n",
    "    if not os.path.exists(os.path.join(output_dir, 'label2id.pkl')):\n",
    "        with codecs.open(os.path.join(output_dir, 'label2id.pkl'), 'wb') as w:\n",
    "            pickle.dump(label_map, w)\n",
    "\n",
    "    textlist = example.text.split(' ')\n",
    "    labellist = example.label.split(' ')\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    for i, word in enumerate(textlist):\n",
    "        token = tokenizer.tokenize(word)\n",
    "        tokens.extend(token)\n",
    "        label_1 = labellist[i]\n",
    "        for m in range(len(token)):\n",
    "            if m == 0:\n",
    "                labels.append(label_1)\n",
    "            else:  \n",
    "                labels.append(\"X\")\n",
    "    if len(tokens) >= max_seq_length - 1:\n",
    "        tokens = tokens[0:(max_seq_length - 2)]\n",
    "        labels = labels[0:(max_seq_length - 2)]\n",
    "    ntokens = []\n",
    "    segment_ids = []\n",
    "    label_ids = []\n",
    "    ntokens.append(\"[CLS]\")  # 句子开始设置 [CLS] 标志\n",
    "    segment_ids.append(0)\n",
    "    label_ids.append(label_map[\"[CLS]\"])  \n",
    "    for i, token in enumerate(tokens):\n",
    "        ntokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "        label_ids.append(label_map[labels[i]])\n",
    "    ntokens.append(\"[SEP]\")  # 句尾添加 [SEP] 标志\n",
    "    segment_ids.append(0)\n",
    "    label_ids.append(label_map[\"[SEP]\"])\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(ntokens)  \n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "        label_ids.append(0)\n",
    "        ntokens.append(\"**NULL**\")\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "    assert len(label_ids) == max_seq_length\n",
    "\n",
    "    feature = InputFeatures(\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids,\n",
    "        label_ids=label_ids,\n",
    "    )\n",
    "   \n",
    "    return feature\n",
    "\n",
    "def filed_based_convert_examples_to_features(\n",
    "        examples, label_list, max_seq_length, tokenizer, output_file, mode=None):\n",
    "    writer = tf.python_io.TFRecordWriter(output_file)\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 5000 == 0:\n",
    "            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "        feature = convert_single_example(ex_index, example, label_list, max_seq_length, tokenizer, output_dir, mode)\n",
    "\n",
    "        def create_int_feature(values):\n",
    "            f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n",
    "            return f\n",
    "\n",
    "        features = collections.OrderedDict()\n",
    "        features[\"input_ids\"] = create_int_feature(feature.input_ids)\n",
    "        features[\"input_mask\"] = create_int_feature(feature.input_mask)\n",
    "        features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n",
    "        features[\"label_ids\"] = create_int_feature(feature.label_ids)\n",
    "        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "\n",
    "train_file = os.path.join(output_dir, \"train.tf_record\")\n",
    "\n",
    "#将训练集中字符转化为features作为训练的输入\n",
    "filed_based_convert_examples_to_features(\n",
    "            train_examples, label_list, max_seq_length, tokenizer, output_file=train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 引入 BiLSTM+CRF 层，作为下游模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-5 \n",
    "dropout_rate = 1.0   \n",
    "lstm_size=1    \n",
    "cell='lstm'\n",
    "num_layers=1\n",
    "\n",
    "from ner.src.models import BLSTM_CRF\n",
    "from tensorflow.contrib.layers.python.layers import initializers\n",
    "\n",
    "def create_model(bert_config, is_training, input_ids, input_mask,\n",
    "                 segment_ids, labels, num_labels, use_one_hot_embeddings,\n",
    "                 dropout_rate=dropout_rate, lstm_size=1, cell='lstm', num_layers=1):\n",
    "    model = modeling.BertModel(\n",
    "        config=bert_config,\n",
    "        is_training=is_training,\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        token_type_ids=segment_ids,\n",
    "        use_one_hot_embeddings=use_one_hot_embeddings\n",
    "    )\n",
    "    embedding = model.get_sequence_output()\n",
    "    max_seq_length = embedding.shape[1].value\n",
    "    used = tf.sign(tf.abs(input_ids))\n",
    "    lengths = tf.reduce_sum(used, reduction_indices=1)  \n",
    "    blstm_crf = BLSTM_CRF(embedded_chars=embedding, hidden_unit=1, cell_type='lstm', num_layers=1,\n",
    "                          dropout_rate=dropout_rate, initializers=initializers, num_labels=num_labels,\n",
    "                          seq_length=max_seq_length, labels=labels, lengths=lengths, is_training=is_training)\n",
    "    rst = blstm_crf.add_blstm_crf_layer(crf_only=True)\n",
    "    return rst\n",
    "\n",
    "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n",
    "                     num_train_steps, num_warmup_steps,use_one_hot_embeddings=False):\n",
    "    #构建模型\n",
    "    def model_fn(features, labels, mode, params):\n",
    "        tf.logging.info(\"*** Features ***\")\n",
    "        for name in sorted(features.keys()):\n",
    "            tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        print('shape of input_ids', input_ids.shape)\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "        total_loss, logits, trans, pred_ids = create_model(\n",
    "            bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
    "            num_labels, False, dropout_rate, lstm_size, cell, num_layers)\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "\n",
    "        if init_checkpoint:\n",
    "            (assignment_map, initialized_variable_names) = \\\n",
    "                 modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
    "            tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "        \n",
    "        output_spec = None\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            train_op = optimization.create_optimizer(\n",
    "                 total_loss, learning_rate, num_train_steps, num_warmup_steps, False)\n",
    "            hook_dict = {}\n",
    "            hook_dict['loss'] = total_loss\n",
    "            hook_dict['global_steps'] = tf.train.get_or_create_global_step()\n",
    "            logging_hook = tf.train.LoggingTensorHook(\n",
    "                hook_dict, every_n_iter=100)\n",
    "\n",
    "            output_spec = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss=total_loss,\n",
    "                train_op=train_op,\n",
    "                training_hooks=[logging_hook])\n",
    "\n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            def metric_fn(label_ids, pred_ids):\n",
    "\n",
    "                return {\n",
    "                    \"eval_loss\": tf.metrics.mean_squared_error(labels=label_ids, predictions=pred_ids),   }\n",
    "            \n",
    "            eval_metrics = metric_fn(label_ids, pred_ids)\n",
    "            output_spec = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss=total_loss,\n",
    "                eval_metric_ops=eval_metrics\n",
    "            )\n",
    "        else:\n",
    "            output_spec = tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions=pred_ids\n",
    "            )\n",
    "        return output_spec\n",
    "\n",
    "    return model_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建模型，开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Num examples = 20864\n",
      "INFO:tensorflow:  Batch size = 64\n",
      "INFO:tensorflow:  Num steps = 1630\n",
      "INFO:tensorflow:Using config: {'_model_dir': './ner/output', '_tf_random_seed': None, '_save_summary_steps': 1000, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fea120f3898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7fea11fa6710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fn = model_fn_builder(\n",
    "        bert_config=bert_config,\n",
    "        num_labels=len(label_list) + 1,\n",
    "        init_checkpoint=init_checkpoint,\n",
    "        learning_rate=learning_rate,\n",
    "        num_train_steps=num_train_steps,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        use_one_hot_embeddings=False)\n",
    "\n",
    "def file_based_input_fn_builder(input_file, seq_length, is_training, drop_remainder):\n",
    "    name_to_features = {\n",
    "        \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "        \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "        \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "        \"label_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "    }\n",
    "\n",
    "    def _decode_record(record, name_to_features):\n",
    "        example = tf.parse_single_example(record, name_to_features)\n",
    "        for name in list(example.keys()):\n",
    "            t = example[name]\n",
    "            if t.dtype == tf.int64:\n",
    "                t = tf.to_int32(t)\n",
    "            example[name] = t\n",
    "        return example\n",
    "\n",
    "    def input_fn(params):\n",
    "        params[\"batch_size\"] = 32\n",
    "        batch_size = params[\"batch_size\"]\n",
    "        d = tf.data.TFRecordDataset(input_file)\n",
    "        if is_training:\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle(buffer_size=300)\n",
    "        d = d.apply(tf.contrib.data.map_and_batch(\n",
    "            lambda record: _decode_record(record, name_to_features),\n",
    "            batch_size=batch_size,\n",
    "            drop_remainder=drop_remainder\n",
    "        ))\n",
    "        return d\n",
    "\n",
    "    return input_fn\n",
    "\n",
    "#训练输入\n",
    "train_input_fn = file_based_input_fn_builder(\n",
    "            input_file=train_file,\n",
    "            seq_length=max_seq_length,\n",
    "            is_training=True,\n",
    "            drop_remainder=True)\n",
    "\n",
    "num_train_size = len(train_examples)\n",
    "\n",
    "tf.logging.info(\"***** Running training *****\")\n",
    "tf.logging.info(\"  Num examples = %d\", num_train_size)\n",
    "tf.logging.info(\"  Batch size = %d\", batch_size)\n",
    "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "#模型预测estimator\n",
    "estimator = tf.estimator.Estimator(\n",
    "        model_fn=model_fn,\n",
    "        config=run_config,\n",
    "        params={\n",
    "        'batch_size':batch_size\n",
    "    })\n",
    "\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在验证集上验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 4631\n",
      "INFO:tensorflow:***** Running evaluation *****\n",
      "INFO:tensorflow:  Num examples = 4631\n",
      "INFO:tensorflow:  Batch size = 64\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?, 128)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input_ids (?, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-11-19-10:44:30\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ner/output/model.ckpt-1630\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-11-19-10:45:01\n",
      "INFO:tensorflow:Saving dict for global step 1630: eval_loss = 0.1202376, global_step = 1630, loss = 34.488083\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1630: ./ner/output/model.ckpt-1630\n",
      "INFO:tensorflow:***** Eval results *****\n",
      "INFO:tensorflow:  eval_loss = 0.1202376\n",
      "INFO:tensorflow:  global_step = 1630\n",
      "INFO:tensorflow:  loss = 34.488083\n"
     ]
    }
   ],
   "source": [
    "eval_examples = processor.get_dev_examples(data_dir)\n",
    "eval_file = os.path.join(output_dir, \"eval.tf_record\")\n",
    "filed_based_convert_examples_to_features(\n",
    "                eval_examples, label_list, max_seq_length, tokenizer, eval_file)\n",
    "data_config['eval.tf_record_path'] = eval_file\n",
    "data_config['num_eval_size'] = len(eval_examples)\n",
    "num_eval_size = data_config.get('num_eval_size', 0)\n",
    "\n",
    "tf.logging.info(\"***** Running evaluation *****\")\n",
    "tf.logging.info(\"  Num examples = %d\", num_eval_size)\n",
    "tf.logging.info(\"  Batch size = %d\", batch_size)\n",
    "\n",
    "eval_steps = None\n",
    "eval_drop_remainder = False\n",
    "eval_input_fn = file_based_input_fn_builder(\n",
    "            input_file=eval_file,\n",
    "            seq_length=max_seq_length,\n",
    "            is_training=False,\n",
    "            drop_remainder=eval_drop_remainder)\n",
    "\n",
    "result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
    "output_eval_file = os.path.join(output_dir, \"eval_results.txt\")\n",
    "with codecs.open(output_eval_file, \"w\", encoding='utf-8') as writer:\n",
    "    tf.logging.info(\"***** Eval results *****\")\n",
    "    for key in sorted(result.keys()):\n",
    "        tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
    "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "if not os.path.exists(data_config_path):\n",
    "    with codecs.open(data_config_path, 'a', encoding='utf-8') as fd:\n",
    "        json.dump(data_config, fd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在测试集上进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 68\n",
      "INFO:tensorflow:***** Running prediction*****\n",
      "INFO:tensorflow:  Num examples = 68\n",
      "INFO:tensorflow:  Batch size = 64\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?, 128)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input_ids (?, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-11-19-10:45:05\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ner/output/model.ckpt-1630\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-11-19-10:45:07\n",
      "INFO:tensorflow:Saving dict for global step 1630: eval_loss = 0.053423714, global_step = 1630, loss = 33.130444\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1630: ./ner/output/model.ckpt-1630\n",
      "INFO:tensorflow:***** Predict results *****\n",
      "INFO:tensorflow:  eval_loss = 0.053423714\n",
      "INFO:tensorflow:  global_step = 1630\n",
      "INFO:tensorflow:  loss = 33.130444\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?, 128)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input_ids (?, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./ner/output/model.ckpt-1630\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:在 香 港 回 归 前 的 最 后 阶 段 ， 中 共 中 央 举 办 《 “ 一 国 两 制 ” 与 香 港 基 本 法 》 讲 座 ， 中 央 领 导 同 志 认 真 听 讲 ， 虚 心 学 习 ， 很 有 意 义 。\n",
      "INFO:tensorflow:O B-LOC I-LOC O O O O O O O O O B-ORG I-ORG I-ORG I-ORG O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:这 表 明 ， 以 江 泽 民 同 志 为 核 心 的 党 中 央 坚 定 不 移 地 贯 彻 邓 小 平 同 志 “ 一 国 两 制 ” 的 伟 大 构 想 ， 不 折 不 扣 地 执 行 基 本 法 。\n",
      "INFO:tensorflow:O O O O O B-PER I-PER I-PER O O O O O O B-ORG I-ORG I-ORG O O O O O O O B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:“ 一 国 两 制 ” 是 邓 小 平 同 志 的 一 个 伟 大 构 想 ， 《 中 华 人 民 共 和 国 香 港 特 别 行 政 区 基 本 法 》 是 贯 彻 落 实 “ 一 国 两 制 ” 伟 大 构 想 的 一 部 全 国 性 法 律 ， 是 一 部 有 鲜 明 中 国 特 色 的 法 律 。\n",
      "INFO:tensorflow:O O O O O O O B-PER I-PER I-PER O O O O O O O O O O O B-LOC I-LOC I-LOC I-LOC I-LOC I-LOC I-LOC B-LOC I-LOC I-LOC I-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:看 包 公 断 案 的 戏 ， 看 他 威 风 凛 凛 坐 公 堂 拍 桌 子 动 刑 具 ， 多 少 还 有 一 点 担 心 ， 总 怕 靠 这 一 套 办 法 弄 出 错 案 来 ， 放 过 了 真 正 的 坏 人 ；\n",
      "INFO:tensorflow:O B-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:可 看 《 包 公 赶 驴 》 这 出 戏 ， 心 里 就 很 踏 实 ： 这 样 是 一 断 一 个 准 的 。\n",
      "INFO:tensorflow:O O O B-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:譬 如 看 《 施 公 案 》 ， 施 大 人 坐 公 堂 问 案 子 不 得 要 领 ， 总 是 扮 成 普 通 百 姓 深 入 民 间 暗 中 查 访 ， 结 果 就 屡 破 奇 案 了 。\n",
      "INFO:tensorflow:O O O O B-PER O O O O B-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:如 果 有 人 问 我 ： “ 你 看 过 许 多 包 公 戏 ， 哪 一 出 最 好 ？ ”\n",
      "INFO:tensorflow:O O O O O O O O O O O O O B-PER I-PER O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:我 要 毫 不 犹 豫 地 回 答 道 ： “ 自 然 是 《 包 公 赶 驴 》 啦 ！\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O B-PER I-PER O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:学 习 基 本 法 顺 利 迎 回 归\n",
      "INFO:tensorflow:O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:本 报 评 论 员\n",
      "INFO:tensorflow:O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:再 过 5 5 天 ， 我 国 政 府 将 对 香 港 恢 复 行 使 主 权 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O B-LOC I-LOC O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:它 把 中 央 对 解 决 香 港 问 题 的 基 本 方 针 政 策 具 体 化 、 法 律 化 ， 成 为 国 家 意 志 。\n",
      "INFO:tensorflow:O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:学 习 基 本 法 ， 顺 利 迎 回 归 ， 是 一 项 迫 切 的 任 务 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:要 学 好 基 本 法 ， 首 先 要 认 识 到 基 本 法 的 意 义 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:说 国 际 意 义 ， 不 只 对 第 三 世 界 ， 而 且 对 全 人 类 都 具 有 长 远 意 义 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:这 是 一 个 具 有 创 造 性 的 杰 作 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:“ 基 本 法 不 仅 为 确 保 香 港 平 稳 过 渡 发 挥 重 要 作 用 ， 也 为 确 保 香 港 长 期 繁 荣 稳 定 发 挥 重 要 作 用 ；\n",
      "INFO:tensorflow:O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:不 仅 为 当 前 解 决 香 港 问 题 发 挥 作 用 ， 也 为 在 不 远 的 将 来 解 决 澳 门 问 题 和 最 终 解 决 台 湾 问 题 ， 实 现 祖 国 完 全 统 一 发 挥 重 要 作 用 。\n",
      "INFO:tensorflow:O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:基 本 法 的 主 要 特 征 ， 是 把 “ 一 国 ” 与 “ 两 制 ” 紧 密 结 合 ， 维 护 国 家 的 主 权 、 统 一 和 领 土 完 整 与 授 权 香 港 特 别 行 政 区 实 行 高 度 自 治 紧 密 结 合 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-LOC I-LOC I-LOC I-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:在 一 个 统 一 的 中 华 人 民 共 和 国 ， 可 以 实 行 社 会 主 义 和 资 本 主 义 两 种 制 度 ， 这 是 为 了 民 族 、 国 家 的 根 本 利 益 。\n",
      "INFO:tensorflow:O O O O O O B-LOC I-LOC I-LOC I-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:只 有 认 真 学 习 ， 才 能 理 解 意 义 ， 认 识 特 征 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:制 定 一 部 好 法 律 ， 很 不 容 易 ；\n",
      "INFO:tensorflow:O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:遵 守 法 律 ， 执 行 法 律 ， 也 很 不 容 易 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:必 须 重 申 ， 有 法 必 依 ， 执 法 必 严 ， 违 法 必 究 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:基 本 法 作 为 一 部 全 国 性 的 法 律 ， 不 仅 香 港 要 严 格 遵 守 ， 各 省 、 自 治 区 、 直 辖 市 都 要 严 格 遵 守 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:从 中 共 中 央 举 办 这 个 讲 座 ， 可 以 看 出 ， 党 和 政 府 正 在 努 力 加 强 法 制 建 设 ， 坚 持 依 法 治 国 。\n",
      "INFO:tensorflow:O B-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:有 了 法 律 ， 有 了 制 度 ， 就 有 了 保 证 ， 就 使 “ 一 国 两 制 ” 的 伟 大 构 想 以 法 律 的 形 式 固 定 下 来 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:全 国 人 民 特 别 是 香 港 同 胞 也 从 中 再 一 次 看 到 ， 中 国 共 产 党 和 人 民 政 府 是 高 度 负 责 任 的 党 和 政 府 ， 一 切 从 人 民 的 利 益 出 发 ， 一 切 为 了 祖 国 的 繁 荣 富 强 ， 香 港 的 明 天 将 更 美 好 。\n",
      "INFO:tensorflow:O O O O O O O B-LOC I-LOC O O O O O O O O O O O B-ORG I-ORG I-ORG I-ORG I-ORG O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:学 习 基 本 法 ， 中 央 领 导 带 了 个 好 头 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:全 党 和 全 国 人 民 特 别 是 各 级 党 政 领 导 干 部 ， 都 要 重 视 学 习 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:只 有 学 习 好 ， 才 能 贯 彻 好 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:为 了 迎 接 香 港 顺 利 回 归 祖 国 这 一 中 华 民 族 的 盛 事 ， 首 先 要 有 一 个 扎 实 的 思 想 准 备 和 良 好 的 精 神 状 态 。\n",
      "INFO:tensorflow:O O O O B-LOC I-LOC O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:基 本 法 连 着 你 我 他\n",
      "INFO:tensorflow:O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:叶 秋\n",
      "INFO:tensorflow:B-PER I-PER\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:赠 书 想 来 是 香 港 同 胞 的 一 种 文 明 礼 仪 。\n",
      "INFO:tensorflow:O O O O O B-LOC I-LOC O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:抵 港 仅 数 日 ， 就 收 到 厚 厚 几 摞 书 。\n",
      "INFO:tensorflow:O B-LOC O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:匆 匆 翻 阅 一 遍 ， 发 现 各 种 版 本 的 《 中 华 人 民 共 和 国 香 港 特 别 行 政 区 基 本 法 》 竟 有 六 册 之 多 ， 推 介 普 及 基 本 法 的 书 籍 还 要 多 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O B-LOC I-LOC I-LOC I-LOC I-LOC I-LOC I-LOC B-LOC I-LOC I-LOC I-LOC I-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:应 约 去 湾 仔 道 谈 事 ， 路 过 一 个 名 为 “ 艺 美 ” 的 书 店 ， 看 到 摆 放 在 最 抢 眼 位 置 的 也 是 基 本 法 及 其 推 介 图 书 。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:O O O B-LOC I-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:由 此 可 见 ， 在 法 制 观 念 很 强 的 港 人 心 目 中 ， 基 本 法 具 有 极 大 的 权 威 和 尊 严 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O B-LOC O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:行 政 官 员 表 示 ： “ 香 港 继 续 繁 荣 稳 定 、 实 现 香 港 梦 的 成 功 要 素 ， 在 基 本 法 中 得 到 了 充 分 保 证 。 ”\n",
      "INFO:tensorflow:O O O O O O O O B-LOC I-LOC O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:法 律 界 人 士 认 为 ： “ 法 治 精 神 能 否 继 续 保 持 ， 基 本 法 已 作 了 明 确 规 定 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:只 要 恪 守 广 大 港 人 认 受 的 香 港 法 律 体 系 中 的 这 个 总 纲 纪 、 总 章 程 ， 香 港 将 健 步 迈 向 新 世 纪 。 ”\n",
      "INFO:tensorflow:O O O O O O B-LOC O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:劳 工 界 的 成 员 说 ， 涉 及 保 障 劳 工 合 法 权 益 的 条 款 ， “ 香 港 现 在 有 的 ， 基 本 法 都 保 持 了 ；\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:大 家 因 此 吃 了 定 心 丸 。 ”\n",
      "INFO:tensorflow:O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:基 本 法 受 到 港 人 的 普 遍 欢 迎 和 高 度 重 视 是 势 所 必 然 。\n",
      "INFO:tensorflow:O O O O O B-LOC O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:历 时 四 年 零 八 个 月 、 凝 聚 了 香 港 和 内 地 无 数 人 的 智 慧 而 制 定 的 基 本 法 ， 将 邓 小 平 同 志 倡 导 的 “ 一 国 两 制 ” 伟 大 构 想 以 法 律 形 式 固 定 下 来 ， 成 为 国 家 和 人 民 的 意 志 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:基 本 法 既 是 香 港 回 归 后 特 区 一 切 运 作 的 法 律 基 础 ， 更 是 保 持 香 港 长 期 稳 定 繁 荣 的 法 律 保 证 。\n",
      "INFO:tensorflow:O O O O O B-LOC I-LOC O O O B-LOC I-LOC O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:实 践 已 经 并 将 继 续 证 明 这 一 点 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:说 来 也 巧 ， 姬 鹏 飞 同 志 1 9 9 0 年 4 月 在 邓 小 平 同 志 题 写 书 名 的 《 基 本 法 的 诞 生 》 一 书 序 言 中 也 写 了 同 样 的 话 。\n",
      "INFO:tensorflow:O O O O O B-PER I-PER I-PER O O O O O O O O O O B-PER I-PER I-PER O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:真 可 谓 仁 者 智 者 所 见 略 同 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:基 本 法 是 一 部 具 有 普 遍 约 束 力 的 重 要 法 律 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:7 月 1 日 ， 这 部 重 要 法 律 即 开 始 正 式 实 施 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:基 本 法 不 仅 体 现 了 香 港 同 胞 的 意 志 和 利 益 ， 也 体 现 了 全 国 人 民 的 意 志 和 利 益 。\n",
      "INFO:tensorflow:O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:正 因 为 如 此 ， 江 泽 民 同 志 强 调 ： 香 港 基 本 法 是 一 部 全 国 性 的 法 律 ， 不 仅 香 港 要 严 格 遵 守 ， 各 省 、 自 治 区 、 直 辖 市 都 要 严 格 遵 守 。\n",
      "INFO:tensorflow:O O O O O O B-PER I-PER I-PER O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:还 表 示 ， 不 仅 我 要 遵 守 ， 我 希 望 香 港 同 胞 和 全 国 1 2 亿 人 民 也 要 遵 守 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:学 习 、 贯 彻 基 本 法 的 过 程 ， 无 疑 是 增 强 法 制 观 念 、 推 进 法 制 建 设 的 过 程 ， 无 疑 是 内 地 和 香 港 在 新 的 征 途 上 并 肩 同 行 、 共 创 辉 煌 的 过 程 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-LOC I-LOC O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:法 律 一 旦 为 人 民 群 众 所 掌 握 ， 就 会 变 成 伟 大 的 力 量 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O O O O O\n",
      "INFO:tensorflow:list index out of range\n",
      "INFO:tensorflow:行 文 至 此 ， 我 对 “ 基 本 法 连 着 你 我 他 ” 有 了 更 深 刻 、 更 真 切 的 理 解 。\n",
      "INFO:tensorflow:O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 370 tokens with 19 phrases; found: 18 phrases; correct: 16.\n",
      "\n",
      "accuracy:  98.92%; precision:  88.89%; recall:  84.21%; FB1:  86.49\n",
      "\n",
      "              LOC: precision: 100.00%; recall: 100.00%; FB1: 100.00  4\n",
      "\n",
      "              ORG: precision: 100.00%; recall: 100.00%; FB1: 100.00  4\n",
      "\n",
      "              PER: precision:  80.00%; recall:  72.73%; FB1:  76.19  10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token_path = os.path.join(output_dir, \"token_test.txt\")\n",
    "if os.path.exists(token_path):\n",
    "    os.remove(token_path)\n",
    "\n",
    "with codecs.open(os.path.join(output_dir, 'label2id.pkl'), 'rb') as rf:\n",
    "    label2id = pickle.load(rf)\n",
    "    id2label = {value: key for key, value in label2id.items()}\n",
    "\n",
    "predict_examples = processor.get_test_examples(data_dir)\n",
    "predict_file = os.path.join(output_dir, \"predict.tf_record\")\n",
    "filed_based_convert_examples_to_features(predict_examples, label_list,\n",
    "                                                 max_seq_length, tokenizer,\n",
    "                                                 predict_file, mode=\"test\")\n",
    "\n",
    "tf.logging.info(\"***** Running prediction*****\")\n",
    "tf.logging.info(\"  Num examples = %d\", len(predict_examples))\n",
    "tf.logging.info(\"  Batch size = %d\", batch_size)\n",
    "    \n",
    "predict_drop_remainder = False\n",
    "predict_input_fn = file_based_input_fn_builder(\n",
    "            input_file=predict_file,\n",
    "            seq_length=max_seq_length,\n",
    "            is_training=False,\n",
    "            drop_remainder=predict_drop_remainder)\n",
    "\n",
    "predicted_result = estimator.evaluate(input_fn=predict_input_fn)\n",
    "output_eval_file = os.path.join(output_dir, \"predicted_results.txt\")\n",
    "with codecs.open(output_eval_file, \"w\", encoding='utf-8') as writer:\n",
    "    tf.logging.info(\"***** Predict results *****\")\n",
    "    for key in sorted(predicted_result.keys()):\n",
    "        tf.logging.info(\"  %s = %s\", key, str(predicted_result[key]))\n",
    "        writer.write(\"%s = %s\\n\" % (key, str(predicted_result[key])))\n",
    "\n",
    "result = estimator.predict(input_fn=predict_input_fn)\n",
    "output_predict_file = os.path.join(output_dir, \"label_test.txt\")\n",
    "\n",
    "def result_to_pair(writer):\n",
    "    for predict_line, prediction in zip(predict_examples, result):\n",
    "        idx = 0\n",
    "        line = ''\n",
    "        line_token = str(predict_line.text).split(' ')\n",
    "        label_token = str(predict_line.label).split(' ')\n",
    "        if len(line_token) != len(label_token):\n",
    "            tf.logging.info(predict_line.text)\n",
    "            tf.logging.info(predict_line.label)\n",
    "        for id in prediction:\n",
    "            if id == 0:\n",
    "                continue\n",
    "            curr_labels = id2label[id]\n",
    "            if curr_labels in ['[CLS]', '[SEP]']:\n",
    "                continue\n",
    "            try:\n",
    "                line += line_token[idx] + ' ' + label_token[idx] + ' ' + curr_labels + '\\n'\n",
    "            except Exception as e:\n",
    "                tf.logging.info(e)\n",
    "                tf.logging.info(predict_line.text)\n",
    "                tf.logging.info(predict_line.label)\n",
    "                line = ''\n",
    "                break\n",
    "            idx += 1\n",
    "        writer.write(line + '\\n')\n",
    "            \n",
    "from ner.src.conlleval import return_report\n",
    "\n",
    "with codecs.open(output_predict_file, 'w', encoding='utf-8') as writer:\n",
    "    result_to_pair(writer)\n",
    "eval_result = return_report(output_predict_file)\n",
    "for line in eval_result:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在线命名实体识别\n",
    "\n",
    "由以上训练得到模型进行在线测试，可以任意输入句子，进行命名实体识别。\n",
    "\n",
    "输入“再见”，结束在线命名实体识别。\n",
    "\n",
    "<span style=\"color:red\">若下述程序未执行成功，则表示训练完成后，GPU显存还在占用，需要restart kernel，然后执行 %run 命令。</span>\n",
    "\n",
    "释放资源具体流程为：菜单 > Kernel > Restart  \n",
    "\n",
    "![释放资源](./img/释放资源.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint path:./ner/output/checkpoint\n",
      "going to restore checkpoint\n",
      "INFO:tensorflow:Restoring parameters from ./ner/output/model.ckpt-1630\n",
      "{1: 'O', 2: 'B-PER', 3: 'I-PER', 4: 'B-ORG', 5: 'I-ORG', 6: 'B-LOC', 7: 'I-LOC', 8: 'X', 9: '[CLS]', 10: '[SEP]'}\n",
      "输入句子:\n",
      "周杰伦（Jay Chou），1979年1月18日出生于台湾省新北市，毕业于淡江中学，中国台湾流行乐男歌手。\n",
      "[['B-PER', 'I-PER', 'I-PER', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "LOC, 台湾省, 新北市, 中国, 台湾\n",
      "PER, 周杰伦, jaycho##u\n",
      "ORG, 淡江中学\n",
      "time used: 0.885981 sec\n",
      "输入句子:\n",
      "马云，1964年9月10日生于浙江省杭州市，1988年毕业于杭州师范学院外语系，同年担任杭州电子工业学院英文及国际贸易教师。\n",
      "[['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "LOC, 浙江省, 杭州市\n",
      "PER, 马云\n",
      "ORG, 杭州师范学院外语系, 杭州电子工业学院\n",
      "time used: 0.041288 sec\n",
      "输入句子:\n",
      "再见\n",
      "\n",
      "再见\n"
     ]
    }
   ],
   "source": [
    "%run ner/src/terminal_predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本案例到此结束"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
